\section{Motivation}
\label{sec:int_motivation}



It's not always easy to understand and introduce new paradigms. Some things we find natural nowadays, were once the source of controversy. Taking for example the number zero $0$. As numbers were introduced to help count physical objects, the idea of representing ``nothingness'' was once considered strange. In the beginning there were numerous ways devised to deal with this mathematical inconvenience, a special case. However the need to use ``zero'' as a number in its own right lead to the popularization of its concept as a number and opened door to new breakthroughs in mathematics\cite{Kaplan2000}. 

Quantum mechanics shared this same problem and the mathematical formalization grew out of the need to explain phenomena at the atomic scale\cite{Mehra1982}. Nowadays we  accepted quantum mechanics as a tool, to analyse and predict behaviour at a microscopic level. However at our scale some quantum mechanics phenomena seem almost ``ridicule'' and paradoxical.

The Quantum Computing started atracting interest in the decade of $1980$, with the works of Yuri Manin and Richard Feynman. The objective was to create a computational machine that could use the entanglement and superposition of the wave function to perform calculations that are currently impossible with classic computers. A popular example of that kind of computation is the prime factorization, which is in the base for modern cryptography. 
However we must bear in mind that our current computers are in fact quantic at the microscopic level. 
Siliccon, a semiconductor, in in the base of modern chips, and its properties arise from quantum mechanics (it is neither a pure conductor, not a isolant material). Sillicon is used to construct transistors that are based on the concept of acurate measuring; in this process the heat productiong is unavoidable. It is the heat produced by the microchips that make them hard to integrate and scale, and despite the Moore's Law that predicts that the number of transistors double every year (in the industry), there are physical limits that cannot be surpassed. When the transistors become too small they will start behaving in a quantum way, introducing errors in our deterministic computations \cite{Laughlin2005}.

The idea of trying to develop in quantum computing arises from the desire to explore this paradigm. The standard curriculum of an undergraduate computer scientist is focused on the current computational paradigm, which has its roots in von Neumman Architecture\cite{neumann45edvac}. While the construction and the inner-workings of computational systems that rely on new paradigms may fall outside of the scope of computer science, understanding it from the point of view of Information Technology and pushing boundaries on model representation are areas where computer scientist might contribute.

A model provides a way to abstract the reality, which is ofen too complex to analyse in its breadth. The Game Theory is an area that tried to find ways to represent and analyse sittuations of conflict generated when intelligent rational beings make decisions. This discipline has major applications in Economics, Biology, Political Science. 
A field that combines both the mathematical foundations of Quantum Mechanics, and the Game Theory is starting to attract attention. These two areas share the same founding father, von Neumman, and creating a Quantum Model for a game seems to be a relevant way to explore the theory behing Quantum Mechanics while having a controlled and creative way to apply it. It is also interesting to analyse how these quantum games differ from their well defined classical counterparts.
